Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Bechtold2020,
author = {Bechtold, Stefan},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Proposal/Lit/Method/CLE{\_}WP{\_}2020{\_}04.pdf:pdf},
title = {{Center for Law {\&} Economics Working Paper Series}},
year = {2020}
}
@article{Prabhumoye2018,
abstract = {Style transfer is the task of rephrasing the text to contain specific stylistic properties without changing the intent or affect within the context. This paper introduces a new method for automatic style transfer. We first learn a latent representation of the input sentence which is grounded in a language translation model in order to better preserve the meaning of the sentence while reducing stylistic properties. Then adversarial generation techniques are used to make the output match the desired style. We evaluate this technique on three different style transformations: sentiment, gender and political slant. Compared to two state-of-the-art style transfer modeling techniques we show improvements both in automatic evaluation of style transfer and in manual evaluation of meaning preservation and fluency.},
archivePrefix = {arXiv},
arxivId = {1804.09000},
author = {Prabhumoye, Shrimai and Tsvetkov, Yulia and Salakhutdinov, Ruslan and Black, Alan W.},
doi = {10.18653/v1/p18-1080},
eprint = {1804.09000},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/StyleTransfer{\_}BackPropagation.pdf:pdf},
isbn = {9781948087322},
journal = {ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
number = {1},
pages = {866--876},
title = {{Style transfer through back-translation}},
volume = {1},
year = {2018}
}
@article{Widmer2020,
author = {Widmer, Philine and Ash, Elliott and Galletta, Sergio},
doi = {10.2139/ssrn.3712218},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/MediaSlantContagious.pdf:pdf},
journal = {SSRN Electronic Journal},
pages = {1--42},
title = {{Media Slant is Contagious}},
year = {2020}
}
@article{Chiang2011,
abstract = {This paper investigates the relationship between media bias and the influence of the media on voting in the context of newspaper endorsements. We first develop a simple econometric model in which voters choose candidates under uncertainty and rely on endorsements from better informed sources. Newspapers are potentially biased in favour of one of the candidates and voters thus rationally account for the credibility of any endorsements. Our primary empirical finding is that endorsements are influential in the sense that voters are more likely to support the recommended candidate after publication of the endorsement. The degree of this influence, however, depends upon the credibility of the endorsement. In this way, endorsements for the Democratic candidate from left-leaning newspapers are less influential than are endorsements from neutral or right-leaning newspapers and likewise for endorsements for the Republican. We also find that endorsements are more influential among moderate voters and those more likely to be exposed to the endorsement. In sum, these findings suggest that voters do rely on the media for information during campaigns but that the extent of this reliance depends upon the degree and direction of any bias. {\textcopyright} The Author 2011.},
author = {Chiang, Chun Fang and Knight, Brian},
doi = {10.1093/restud/rdq037},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/rdq037.pdf:pdf},
issn = {1467937X},
journal = {Review of Economic Studies},
keywords = {Endorsements,Media bias,Voting},
number = {3},
pages = {795--820},
title = {{Media bias and influence: Evidence from newspaper endorsements}},
volume = {78},
year = {2011}
}
@article{Ash2017,
abstract = {This article provides a theoretical and empirical analysis of how politicians allocate their time across issues. When voters are uncertain about an incumbent's preferences, there is a pervasive incentive to "posture" by spending too much time on divisive issues (which are more informative about a politician's preferences) at the expense of time spent on common-values issues (which provide greater benefit to voters). Higher transparency over the politicians' choices can exacerbate the distortions. These theoretical results motivate an empirical study of how Members of the US Congress allocate time across issues in their floor speeches. We find that US senators spend more time on divisive issues when they are up for election, consistent with electorally induced posturing. In addition, we find that US house members spend more time on divisive issues in response to higher news transparency.},
author = {Ash, Elliott and Morelli, Massimo and {Van Weelden}, Richard},
doi = {10.1086/692587},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/692587.pdf:pdf},
issn = {14682508},
journal = {Journal of Politics},
number = {4},
pages = {1268--1285},
title = {{Elections and divisiveness: Theory and evidence}},
volume = {79},
year = {2017}
}
@article{Gentzkow2010,
abstract = {We construct a new index of media slant that measures whether a news outlet's language is more similar to a congressional Republican or Democrat. We apply the measure to study the market forces that determine political content in the news. We estimate a model of newspaper demand that incorporates slant explicitly, estimate the slant that would be chosen if newspapers independently maximized their own pro{\ldots}ts, and compare these ideal points with {\ldots}rms'actual choices. Our analysis con{\ldots}rms an economically signi{\ldots}cant demand for news slanted toward one's own political ideology. Firms respond strongly to consumer preferences, which account for roughly 20 percent of the variation in measured slant in our sample. By contrast, the identity of a newspaper's owner explains far less of the variation in slant, and we {\ldots}nd little evidence that media conglomerates homogenize news to minimize {\ldots}xed costs in the production of content.},
author = {Gentzkow, Matthew and Shapiro, Jesse M},
doi = {10.3982/ecta7195},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/25621396.pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
keywords = {bias,media ownership,text categorization},
number = {1},
pages = {35--71},
title = {{What Drives Media Slant? Evidence From U.S. Daily Newspapers}},
volume = {78},
year = {2010}
}
@article{Lauderdale2016,
author = {Lauderdale, Benjamin E and Herzog, Alexander},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/26349743.pdf:pdf},
journal = {Political Analysis},
number = {3},
pages = {374--394},
title = {{Measuring Political Positions from Legislative Speech}},
volume = {24},
year = {2016}
}
@article{Slapin2008,
abstract = {Recent advances in computational content analysis have provided scholars promising new ways for estimating party positions. However, existing text-based methods face challenges in producing valid and reliable time-series data. This article proposes a scaling algorithm called WORDFISH to estimate policy positions based on word frequencies in texts. The technique allows researchers to locate parties in one or multiple elections. We demonstrate the algorithm by estimating the positions of German political parties from 1990 to 2005 using word frequencies in party manifestos. The extracted positions reflect changes in the party system more accurately than existing time-series estimates. In addition, the method allows researchers to examine which words are important for placing parties on the left and on the right. We find that words with strong political connotations are the best discriminators between parties. Finally, a series of robustness checks demonstrate that the estimated positions are insensitive to distributional assumptions and document selection. {\textcopyright} 2008, Midwest Political Science Association.},
author = {Slapin, Jonathan B. and Proksch, Sven Oliver},
doi = {10.1111/j.1540-5907.2008.00338.x},
file = {:C$\backslash$:/Users/nicol/Dropbox/Studium/Amsterdam/Studies/Semester 4/Master Thesis/Lit/Method/wordfish/slapin{\_}proksch{\_}ajps{\_}2008.pdf:pdf},
issn = {00925853},
journal = {American Journal of Political Science},
number = {3},
pages = {705--722},
title = {{A scaling model for estimating time-series party positions from Texts}},
volume = {52},
year = {2008}
}
@article{Gentzkow2011,
abstract = {We use new data on entries and exits of US daily newspapers from 1869 to 2004 to estimate effects on political participation, party vote shares, and electoral competitiveness. Our identification strategy exploits the precise timing of these events and allows for the possibility of confounding trends. We focus our analysis on the years 1869- 1928, and we use the remaining years of data to look at changes over time. We find that newspapers have a robust positive effect on political participation, with one additional newspaper increasing both presidential and congressional turnout by approximately 0.3 percentage points. Newspaper competition is not a key driver of turnout: our effect is driven mainly by the first newspaper in a market, and the effect of a second or third paper is significantly smaller. The effect on presidential turnout diminishes after the introduction of radio and television, while the estimated effect on congressional turnout remains similar up to recent years. We find no evidence that partisan newspapers affect party vote shares, with confidence intervals that rule out even moderate-sized effects. We find no clear evidence that newspapers systematically help or hurt incumbents.},
author = {Gentzkow, Matthew and Shapiro, Jesse M. and Sinkinson, Michael},
doi = {10.1257/aer.101.7.2980},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/aer.101.7.2980.pdf:pdf},
issn = {00028282},
journal = {American Economic Review},
number = {7},
pages = {2980--3018},
title = {{The effect of newspaper entry and exit on electoral politics}},
volume = {101},
year = {2011}
}
@article{Hjorth2015,
abstract = {Assigning political actors positions in ideological space is a task of key importance to political scientists. In this paper we compare estimates obtained using the automated Wordscores and Wordfish techniques, along with estimates from voters and the Comparative Manifesto Project (CMP), against expert placements. We estimate the positions of 254 manifestos across 33 elections in Germany and Denmark, two cases with very different textual data available. We find that Wordscores approximately replicates the CMP, voter, and expert assessments of party positions in both cases, whereas Wordfish replicates the positions in the German manifestos only. The results demonstrate that automated methods can produce valid estimates of party positions, but also that the appropriateness of each method hinges on the quality of the textual data. Additional analyses suggest that Wordfish requires both longer texts and a more ideologically charged vocabulary in order to produce estimates comparable to Wordscores. The paper contributes to the literature on automated content analysis by providing a comprehensive test of convergent validation, in terms of both number of cases analyzed and number of validation measures.},
author = {Hjorth, Frederik and Klemmensen, Robert and Hobolt, Sara B. and Hansen, Martin Ejnar and Kurrild-Klitgaard, Peter},
doi = {10.1177/2053168015580476},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/2053168015580476.pdf:pdf},
issn = {20531680},
journal = {Research and Politics},
keywords = {Automated content analysis,CMP,Party positions,Text as data,Wordfish,Wordscores},
number = {2},
title = {{Computers, coders, and voters: Comparing automated methods for estimating party positions}},
volume = {2},
year = {2015}
}
@article{Lauderdale2016,
abstract = {Existing approaches to measuring political disagreement from text data perform poorly except when applied to narrowly selected texts discussing the same issues and written in the same style. We demonstrate the first viable approach for estimating legislator-specific scores from the entire speech corpus of a legislature, while also producing extensive information about the evolution of speech polarization and politically loaded language. In the Irish D{\'{a}}il, we show that the dominant dimension of speech variation is government-opposition, with ministers more extreme on this dimension than backbenchers, and a second dimension distinguishing between the establishment and anti-establishment opposition parties. In the U.S. Senate, we estimate a dimension that has moderate within-party correlations with scales based on roll-call votes and campaign donation patterns; however, we observe greater overlap across parties in speech positions than roll-call positions and partisan polarization in speeches varies more clearly in response to major political events.},
author = {Lauderdale, Benjamin E. and Herzog, Alexander},
doi = {10.1093/pan/mpw017},
file = {:C$\backslash$:/Users/nicol/Dropbox/Studium/Amsterdam/Studies/Semester 4/Master Thesis/Lit/Method/Lauderdale{\_}Herzog{\_}PA{\_}2016.pdf:pdf},
issn = {14764989},
journal = {Political Analysis},
number = {3},
pages = {374--394},
title = {{Measuring political positions from legislative speech}},
volume = {24},
year = {2016}
}
@unpublished{Krause2021,
author = {Krause, Werner and Berk, Nicolai},
title = {{Right-Wing Terrorist Attacks, the Media's Reactions, and Radical Right Party Support}},
year = {2021}
}
@article{Vig2020,
abstract = {Common methods for interpreting neural models in natural language processing typically examine either their structure or their behavior, but not both. We propose a methodology grounded in the theory of causal mediation analysis for interpreting which parts of a model are causally implicated in its behavior. It enables us to analyze the mechanisms by which information flows from input to output through various model components, known as mediators. We apply this methodology to analyze gender bias in pre-trained Transformer language models. We study the role of individual neurons and attention heads in mediating gender bias across three datasets designed to gauge a model's sensitivity to gender bias. Our mediation analysis reveals that gender bias effects are (i) sparse, concentrated in a small part of the network; (ii) synergistic, amplified or repressed by different components; and (iii) decomposable into effects flowing directly from the input and indirectly through the mediators.
MSC Codes 68T50},
archivePrefix = {arXiv},
arxivId = {2004.12265},
author = {Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Singer, Yaron and Shieber, Stuart},
eprint = {2004.12265},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Lit/2004.12265.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Causal mediation analysis for interpreting neural NLP: The case of gender bias}},
year = {2020}
}
@book{Plato520a,
author = {Plato},
title = {{Republic}}
}
@article{Bilbao-Jayo2018,
abstract = {In this article, the authors propose a new approach to automate the analysis of the political discourse of the citizens and public servants, to allow public administrations to better react to their needs and claims. The tool presented in this article can be applied to the analysis of the underlying political themes in any type of text, in order to better understand the reasons behind it. To do so, the authors have built a discourse classifier using multi-scale convolutional neural networks in seven different languages: Spanish, Finnish, Danish, English, German, French, and Italian. Each of the language-specific discourse classifiers has been trained with sentences extracted from annotated parties' election manifestos. The analysis proves that enhancing the multi-scale convolutional neural networks with context data improves the political analysis results.},
author = {Bilbao-Jayo, Aritz and Almeida, Aitor},
doi = {10.1177/1550147718811827},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/1550147718811827.pdf:pdf},
issn = {15501477},
journal = {International Journal of Distributed Sensor Networks},
keywords = {Supervised classification,convolutional neural networks,online political discourse,sentence classification},
number = {11},
title = {{Automatic political discourse analysis with multi-scale convolutional neural networks and contextual data}},
volume = {14},
year = {2018}
}
@article{Laver2003,
abstract = {We present a new way of extracting policy positions from political texts that treats texts not as discourses to be understood and interpreted but rather, as data in the form of words. We compare this approach to previous methods of text analysis and use it to replicate published estimates of the policy positions of political parties in Britain and Ireland, on both economic and social policy dimensions. We "export" the method to a non-English-language environment, analyzing the policy positions of German parties, including the PDS as it entered the former West German party system. Finally, we extend its application beyond the analysis of party manifestos, to the estimation of political positions from legislative speeches. Our "language-blind" word scoring technique successfully replicates published policy estimates without the substantial costs of time and labor that these require. Furthermore, unlike in any previous method for extracting policy positions from political texts, we provide uncertainty measures for our estimates, allowing analysts to make informed judgments of the extent to which differences between two estimated policy positions can be viewed as significant or merely as products of measurement error.},
author = {Laver, Michael and Benoit, Kenneth and Garry, John},
doi = {10.1017/S0003055403000698},
file = {:C$\backslash$:/Users/nicol/Dropbox/Studium/Amsterdam/Studies/Semester 4/Master Thesis/Lit/Method/extracting{\_}policy{\_}positions{\_}from{\_}political{\_}texts{\_}using{\_}words{\_}as{\_}data.pdf:pdf},
isbn = {0003055403000},
issn = {00030554},
journal = {American Political Science Review},
number = {2},
pages = {311--331},
publisher = {UVA Universiteitsbibliotheek},
title = {{Extracting policy positions from political texts using words as data}},
volume = {97},
year = {2003}
}
@article{Peterson2018,
abstract = {Measuring the polarization of legislators and parties is a key step in understanding how politics develops over time. But in parliamentary systems-where ideological positions estimated from roll calls may not be informative-producing valid estimates is extremely challenging. We suggest a new measurement strategy that makes innovative use of the accuracy of machine classifiers, i.e., the number of correct predictions made as a proportion of all predictions. In our case, the labels are the party identifications of the members of parliament, predicted from their speeches along with some information on debate subjects. Intuitively, when the learner is able to discriminate members in the two main Westminster parties well, we claim we are in a period of high polarization. By contrast, when the classifier has low accuracy- A nd makes a relatively large number of mistakes in terms of allocating members to parties based on the data-we argue parliament is in an era of low polarization. This approach is fast and substantively valid, and we demonstrate its merits with simulations, and by comparing the estimates from 78 years of House of Commons speeches with qualitative and quantitative historical accounts of the same. As a headline finding, we note that contemporary British politics is approximately as polarized as it was in the mid-1960s-that is, in the middle of the postwar consensus. More broadly, we show that the technical performance of supervised learning algorithms can be directly informative about substantive matters in social science.},
author = {Peterson, Andrew and Spirling, Arthur},
doi = {10.1017/pan.2017.39},
file = {:C$\backslash$:/Users/nicol/Dropbox/Studium/Amsterdam/Studies/Semester 4/Master Thesis/Lit/Method/classification{\_}accuracy{\_}as{\_}a{\_}substantive{\_}quantity{\_}of{\_}interest{\_}measuring{\_}polarization{\_}in{\_}westminster{\_}systems.pdf:pdf},
issn = {14764989},
journal = {Political Analysis},
keywords = {Statistical analysis of texts,learning,polarization},
number = {1},
pages = {120--128},
title = {{Classification Accuracy as a Substantive Quantity of Interest: Measuring Polarization in Westminster Systems}},
volume = {26},
year = {2018}
}
@article{Brauninger2013,
abstract = {Numerous empirical studies in political science use estimates of policy positions of parties and political elites to analyse how preferences shape outcomes in decision-making processes. In the past decade, data availability and methodological advances have fostered the shift from a static, cross-sectional to a dynamic, longitudinal perspective on changing preferences and political change. The current debate on which kind of data can be used for longitudinal analysis concentrates on the pros and cons of the ‘Comparative Manifesto Project' dataset and methods based on fully computerized content analysis of political texts. In this paper, we compare estimates on parties policy position on a left-right-axis using CMP data and data derived from wordscores for 13 Western European countries in the time period between 1960 and 2000. Our analysis shows that applying wordscores results in similar estimates of patterns of party positions on a general left-right dimension compared to the CMP data, which, however, strongly differ by the countries under investigation. We examine outliers from the overall pattern and discuss possible reasons for them.},
author = {Br{\"{a}}uninger, Thomas and Debus, Marc and M{\"{u}}ller, J},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/wp{\_}153.pdf:pdf},
journal = {Conference of the Midwest Political Science Association},
title = {{Estimating hand-and computer-coded policy positions of political actors across countries and time}},
year = {2013}
}
@article{Devlin2019,
abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5{\%} (7.7{\%} point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
archivePrefix = {arXiv},
arxivId = {1810.04805},
author = {Devlin, Jacob and Chang, Ming Wei and Lee, Kenton and Toutanova, Kristina},
eprint = {1810.04805},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/1810.04805.pdf:pdf},
isbn = {9781950737130},
journal = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
number = {Mlm},
pages = {4171--4186},
title = {{BERT: Pre-training of deep bidirectional transformers for language understanding}},
volume = {1},
year = {2019}
}
@article{Gentzkow2019a,
abstract = {We study the problem of measuring group differences in choices when the dimensionality of the choice set is large. We show that standard approaches suffer from a severe finite‐sample bias, and we propose an estimator that applies recent advances in machine learning to address this bias. We apply this method to measure trends in the partisanship of congressional speech from 1873 to 2016, defining partisanship to be the ease with which an observer could infer a congressperson's party from a single utterance. Our estimates imply that partisanship is far greater in recent years than in the past, and that it increased sharply in the early 1990s after remaining low and relatively constant over the preceding century.},
author = {Gentzkow, Matthew and Shapiro, Jesse M. and Taddy, Matt},
doi = {10.3982/ecta16566},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/ECTA16566.pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
keywords = {Partisanship, polarization, machine learning, text},
number = {4},
pages = {1307--1340},
title = {{Measuring Group Differences in High‐Dimensional Choices: Method and Application to Congressional Speech}},
volume = {87},
year = {2019}
}
@article{Simoes2020,
abstract = {In this paper, we apply Bidirectional Encoder Representations from Transformers (BERT) to detect political ideologies in congressional debate transcripts from 2005. For this task, the Ideological Books Corpus (IBC) data set was used, which contains 4,062 sentences annotated for political ideology. Using fine tuned BERT the accuracy achieved was 68{\%}. The F1 Score achieved was 65{\%}, which is more than 30 percentage points higher than former implementations.},
author = {Simoes, Alexandre and {Del Mar Casta{\~{n}}os}, Maria},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/report43.pdf:pdf},
number = {2017},
pages = {1--5},
title = {{Fine-Tuned BERT for the Detection of Political Ideology Stanford CS224N Custom Project}},
volume = {6},
year = {2020}
}
@article{Ecker2021,
abstract = {This paper examines the validity of three approaches to estimate party positions on the general left–right and EU dimensions. We newly introduce party elite data from the comprehensive IntUne survey and cross-validate it with existing expert survey and manifesto data. The general left–right estimates generated by elites and experts show a higher congruence than those derived from party manifestos; neither measure clearly materializes as more valid regarding EU positions. We identify which factors explain diverging estimates. For instance, disagreement among experts has greater impact than their mere number. The substantial centrist bias of the manifesto estimates persists even when alternative documents are used to substitute manifestos. Low response rates among elites have no systematic detrimental effect on the validity of party position estimates.},
author = {Ecker, Alejandro and Jenny, Marcelo and M{\"{u}}ller, Wolfgang C and Praprotnik, Katrin},
doi = {10.1177/1354068821990298},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/1354068821990298.pdf:pdf},
issn = {1354-0688},
journal = {Party Politics},
keywords = {cross-validation,elite surveys,european integration,expert surveys,left,right party positions},
pages = {135406882199029},
title = {{How and why party position estimates from manifestos, expert, and party elite surveys diverge. A comparative analysis of the ‘left–right' and the ‘European integration' dimensions}},
year = {2021}
}
@article{Koljonen2020,
abstract = {It is often claimed that computational methods for examining textual data give good enough party position estimates at a fraction of the costs of many non-computational methods. However, the conclusive testing of these claims is still far from fully accomplished. We compare the performance of two computational methods, Wordscores and Wordfish, and four non-computational methods in estimating the political positions of parties in two dimensions, a left-right dimension and a progressive-conservative dimension. Our data comprise electoral party manifestos written in Finnish and published in Finland. The non-computational estimates are composed of the Chapel Hill Expert Survey estimates, the Manifesto Project estimates, estimates deriving from survey-based data on voter perceptions of party positions, and estimates derived from electoral candidates' replies to voting advice application questions. Unlike Wordfish, Wordscores generates relatively well-performing estimates for many of the party positions, but despite this does not offer an even match to the non-computational methods.},
author = {Koljonen, Juha and Isotalo, Veikko and Ahonen, Pertti and Mattila, Mikko},
doi = {10.1177/1354068820974609},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/1354068820974609.pdf:pdf},
issn = {14603683},
journal = {Party Politics},
keywords = {Wordfish,Wordscores,manifestos,parties,quantitative content analysis},
number = {May},
title = {{Comparing computational and non-computational methods in party position estimation: Finland, 2003–2019}},
year = {2020}
}
@article{Ladd2009,
abstract = {Using panel data and matching techniques, we exploit a rare change in communication flows - the endorsement switch to the Labour Party by several prominent British newspapers before the 1997 United Kingdom general election - to study the persuasive power of the news media. These unusual endorsement switches provide an opportunity to test for news media persuasion while avoiding methodological pitfalls that have plagued previous studies. By comparing readers of newspapers that switched endorsements to similar individuals who did not read these newspapers, we estimate that these papers persuaded a considerable share of their readers to vote for Labour. Depending on the statistical approach, the point estimates vary from about 10{\%} to as high as 25{\%} of readers. These findings provide rare evidence that the news media exert a powerful influence on mass political behavior. {\textcopyright} 2009 Midwest Political Science Association.},
author = {Ladd, Jonathan Mc Donald and Lenz, Gabriel S.},
doi = {10.1111/j.1540-5907.2009.00377.x},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/j.1540-5907.2009.00377.x.pdf:pdf},
issn = {00925853},
journal = {American Journal of Political Science},
number = {2},
pages = {394--410},
title = {{Exploiting a rare communication shift to document the persuasive power of the news media}},
volume = {53},
year = {2009}
}
@article{Lelkes2017,
abstract = {Over the last two decades, as the number of media choices available to consumers has exploded, so too have worries over self-selection into media audiences. Some fear greater apathy, others heightened polarization. In this article, we shed light on the latter possibility. We identify the impact of access to broadband Internet on affective polarization by exploiting differences in broadband availability brought about by variation in state right-of-way regulations (ROW). We merge state-level regulation data with county-level broadband penetration data and a large-N sample of survey data from 2004 to 2008 and find that access to broadband Internet increases partisan hostility. The effect occurs in both years and is stable across levels of political interest. We also find that access to broadband Internet boosts partisans' consumption of partisan media, a likely cause of increased polarization.},
author = {Lelkes, Yphtach and Sood, Gaurav and Iyengar, Shanto},
doi = {10.1111/ajps.12237},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/LelkesMediaPolarisation.pdf:pdf},
issn = {15405907},
journal = {American Journal of Political Science},
number = {1},
pages = {5--20},
title = {{The Hostile Audience: The Effect of Access to Broadband Internet on Partisan Affect}},
volume = {61},
year = {2017}
}

@misc{GLES2017RCS,
author = {Ro{\ss}teutscher, Sigrid and Schoen, Harald and Schmitt-Beck, R{\"{u}}diger and We{\ss}els, Bernhard and Wolf, Christof and Staudt, Alexander},
doi = {ZA6803 Datenfile Version 4.0.1, 10.4232/1.13213.},
publisher = {GESIS Datenarchiv, K{\"{o}}ln},
title = {{Rolling Cross-Section Wahlkampfstudie mit Nachwahl-Panelwelle (GLES 2017)}},
year = {2019}
}

@unpublished{Osnabrugge2020,
author = {Osnabr{\"{u}}gge, Moritz and Ash, Elliott and Morelli, Massimo},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project/nlpdl{\_}project/Lit/CLE{\_}WP{\_}2020{\_}04.pdf:pdf},
institution = {ETH Z{\"{u}}rich},
mendeley-groups = {PhD/Courses/NLPDL},
series = {Center for Law {\&} Economics Working Paper Series},
title = {{Cross-Domain Topic Classification for Political Texts}},
year = {2020}
}

@misc{R,
abstract = {R Core Team (2014). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL http://www.R-project.org/.},
address = {Vienna, Austria},
author = {{R Development Core Team 3.0.1.}},
booktitle = {R Foundation for Statistical Computing},
publisher = {R Foundation for Statistical Computing},
title = {{A Language and Environment for Statistical Computing}},
url = {http://www.r-project.org},
year = {2013}
}

@book{python,
 author = {Van Rossum, Guido and Drake, Fred L.},
 title = {Python 3 Reference Manual},
 year = {2009},
 isbn = {1441412697},
 publisher = {CreateSpace},
 address = {Scotts Valley, CA}
}

@misc{wolf2020huggingfaces,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@article{DBLP,
  author    = {Timothy Niven and
               Hung{-}Yu Kao},
  title     = {Probing Neural Network Comprehension of Natural Language Arguments},
  journal   = {CoRR},
  volume    = {abs/1907.07355},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.07355},
  archivePrefix = {arXiv},
  eprint    = {1907.07355},
  timestamp = {Tue, 23 Jul 2019 10:54:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-07355.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}