%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Jankin at 2019-06-23 08:30:59 +0100 


%% Saved with string encoding Unicode (UTF-8) 

@unpublished{Krause2021,
author = {Krause, Werner and Berk, Nicolai},
mendeley-groups = {PhD/Courses/NLPDL},
title = {{Right-Wing Terrorist Attacks, the Media's Reactions, and Radical Right Party Support}},
year = {2021}
}

@book{Plato520a,
author = {Plato},
mendeley-groups = {PhD/Courses/NLPDL},
title = {{Republic}}
}

@article{Vig2020,
abstract = {Common methods for interpreting neural models in natural language processing typically examine either their structure or their behavior, but not both. We propose a methodology grounded in the theory of causal mediation analysis for interpreting which parts of a model are causally implicated in its behavior. It enables us to analyze the mechanisms by which information flows from input to output through various model components, known as mediators. We apply this methodology to analyze gender bias in pre-trained Transformer language models. We study the role of individual neurons and attention heads in mediating gender bias across three datasets designed to gauge a model's sensitivity to gender bias. Our mediation analysis reveals that gender bias effects are (i) sparse, concentrated in a small part of the network; (ii) synergistic, amplified or repressed by different components; and (iii) decomposable into effects flowing directly from the input and indirectly through the mediators.
MSC Codes 68T50},
archivePrefix = {arXiv},
arxivId = {2004.12265},
author = {Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Singer, Yaron and Shieber, Stuart},
eprint = {2004.12265},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Lit/2004.12265.pdf:pdf},
issn = {23318422},
journal = {arXiv},
mendeley-groups = {PhD/Courses/NLPDL},
title = {{Causal mediation analysis for interpreting neural NLP: The case of gender bias}},
year = {2020}
}


@article{Bilbao-Jayo2018,
abstract = {In this article, the authors propose a new approach to automate the analysis of the political discourse of the citizens and public servants, to allow public administrations to better react to their needs and claims. The tool presented in this article can be applied to the analysis of the underlying political themes in any type of text, in order to better understand the reasons behind it. To do so, the authors have built a discourse classifier using multi-scale convolutional neural networks in seven different languages: Spanish, Finnish, Danish, English, German, French, and Italian. Each of the language-specific discourse classifiers has been trained with sentences extracted from annotated parties' election manifestos. The analysis proves that enhancing the multi-scale convolutional neural networks with context data improves the political analysis results.},
author = {Bilbao-Jayo, Aritz and Almeida, Aitor},
doi = {10.1177/1550147718811827},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/1550147718811827.pdf:pdf},
issn = {15501477},
journal = {International Journal of Distributed Sensor Networks},
keywords = {Supervised classification,convolutional neural networks,online political discourse,sentence classification},
mendeley-groups = {PhD/Courses/NLPDL},
number = {11},
title = {{Automatic political discourse analysis with multi-scale convolutional neural networks and contextual data}},
volume = {14},
year = {2018}
}


@article{Laver2003,
abstract = {We present a new way of extracting policy positions from political texts that treats texts not as discourses to be understood and interpreted but rather, as data in the form of words. We compare this approach to previous methods of text analysis and use it to replicate published estimates of the policy positions of political parties in Britain and Ireland, on both economic and social policy dimensions. We "export" the method to a non-English-language environment, analyzing the policy positions of German parties, including the PDS as it entered the former West German party system. Finally, we extend its application beyond the analysis of party manifestos, to the estimation of political positions from legislative speeches. Our "language-blind" word scoring technique successfully replicates published policy estimates without the substantial costs of time and labor that these require. Furthermore, unlike in any previous method for extracting policy positions from political texts, we provide uncertainty measures for our estimates, allowing analysts to make informed judgments of the extent to which differences between two estimated policy positions can be viewed as significant or merely as products of measurement error.},
author = {Laver, Michael and Benoit, Kenneth and Garry, John},
doi = {10.1017/S0003055403000698},
file = {:C$\backslash$:/Users/nicol/Dropbox/Studium/Amsterdam/Studies/Semester 4/Master Thesis/Lit/Method/extracting{\_}policy{\_}positions{\_}from{\_}political{\_}texts{\_}using{\_}words{\_}as{\_}data.pdf:pdf},
isbn = {0003055403000},
issn = {00030554},
journal = {American Political Science Review},
mendeley-groups = {RMSS/MAster Thesis,PhD/Courses/NLPDL},
number = {2},
pages = {311--331},
publisher = {UVA Universiteitsbibliotheek},
title = {{Extracting policy positions from political texts using words as data}},
volume = {97},
year = {2003}
}

@article{Simoes2020,
abstract = {In this paper, we apply Bidirectional Encoder Representations from Transformers (BERT) to detect political ideologies in congressional debate transcripts from 2005. For this task, the Ideological Books Corpus (IBC) data set was used, which contains 4,062 sentences annotated for political ideology. Using fine tuned BERT the accuracy achieved was 68{\%}. The F1 Score achieved was 65{\%}, which is more than 30 percentage points higher than former implementations.},
author = {Simoes, Alexandre and {Del Mar Casta{\~{n}}os}, Maria},
file = {:C$\backslash$:/Users/nicol/Dropbox/PhD/Courses/Year 1/NLPDL/Project Proposal/Lit/report43.pdf:pdf},
mendeley-groups = {PhD/Courses/NLPDL},
number = {2017},
pages = {1--5},
title = {{Fine-Tuned BERT for the Detection of Political Ideology Stanford CS224N Custom Project}},
volume = {6},
year = {2020}
}


@article{chatsiou_text_2020,
	title = {Text {Classification} of {Manifestos} and {COVID}-19 {Press} {Briefings} using {BERT} and {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2010.10267},
	abstract = {We build a sentence-level political discourse classifier using existing human expert annotated corpora of political manifestos from the Manifestos Project (Volkens et al., 2020a) and applying them to a corpus ofCOVID-19Press Briefings (Chatsiou, 2020). We use manually annotated political manifestos as training data to train a local topic ConvolutionalNeural Network (CNN) classifier; then apply it to the COVID-19PressBriefings Corpus to automatically classify sentences in the test corpus.We report on a series of experiments with CNN trained on top of pre-trained embeddings for sentence-level classification tasks. We show thatCNN combined with transformers like BERT outperforms CNN combined with other embeddings (Word2Vec, Glove, ELMo) and that it is possible to use a pre-trained classifier to conduct automatic classification on different political texts without additional training.},
	urldate = {2021-03-28},
	journal = {arXiv:2010.10267 [cs]},
	author = {Chatsiou, Kakia},
	month = nov,
	year = {2020},
	note = {arXiv: 2010.10267},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, 68T07, 91F10, J.4, J.5},
	annote = {Comment: 12 pages, 1 figure, 4 tables},
	file = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2010.10267.pdf:application/pdf}
}

@InProceedings{Spinde2020,
  author     = {Spinde, Timo and Hamborg, Felix and Gipp, Bela},
  booktitle  = {{ECML} {PKDD} 2020 {Workshops}},
  title      = {Media {Bias} in {German} {News} {Articles}: {A} {Combined} {Approach}},
  doi        = {10.1007/978-3-030-65965-3_41},
  editor     = {Koprinska, Irena and Kamp, Michael and Appice, Annalisa and Loglisci, Corrado and Antonie, Luiza and Zimmermann, Albrecht and Guidotti, Riccardo and Özgöbek, Özlem and Ribeiro, Rita P. and Gavaldà, Ricard and Gama, João and Adilova, Linara and Krishnamurthy, Yamuna and Ferreira, Pedro M. and Malerba, Donato and Medeiros, Ibéria and Ceci, Michelangelo and Manco, Giuseppe and Masciari, Elio and Ras, Zbigniew W. and Christen, Peter and Ntoutsi, Eirini and Schubert, Erich and Zimek, Arthur and Monreale, Anna and Biecek, Przemyslaw and Rinzivillo, Salvatore and Kille, Benjamin and Lommatzsch, Andreas and Gulla, Jon Atle},
  isbn       = {9783030659653},
  language   = {en},
  pages      = {581--590},
  publisher  = {Springer International Publishing},
  series     = {Communications in {Computer} and {Information} {Science}},
  abstract   = {Slanted news coverage, also called media bias, can heavily influence how news consumers interpret and react to the news. Models to identify and describe biases have been proposed across various scientific fields, focusing mostly on English media. In this paper, we propose a method for analyzing media bias in German media. We test different natural language processing techniques and combinations thereof. Specifically, we combine an IDF-based component, a specially created bias lexicon, and a linguistic lexicon. We also flexibly extend our lexica by the usage of word embeddings. We evaluate the system and methods in a survey (N = 46), comparing the bias words our system detected to human annotations. So far, the best component combination results in an F11\_\{1\} score of 0.31 of words that were identified as biased by our system and our study participants. The low performance shows that the analysis of media bias is still a difficult task, but using fewer resources, we achieved the same performance on the same task than recent research on English. We summarize the next steps in improving the resources and the overall results.},
  address    = {Cham},
  file       = {Springer Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2F978-3-030-65965-3_41.pdf:application/pdf},
  keywords   = {Media bias , News slant , News bias , Content analysis , Frame analysis },
  shorttitle = {Media {Bias} in {German} {News} {Articles}},
  year       = {2020},
}

@TechReport{Terechshenko2020,
  author     = {Terechshenko, Zhanna and Linder, Fridolin and Padmakumar, Vishakh and Liu, Michael and Nagler, Jonathan and Tucker, Joshua A. and Bonneau, Richard},
  title      = {A {Comparison} of {Methods} in {Political} {Science} {Text} {Classification}: {Transfer} {Learning} {Language} {Models} for {Politics}},
  doi        = {10.2139/ssrn.3724644},
  language   = {en},
  number     = {ID 3724644},
  type       = {{SSRN} {Scholarly} {Paper}},
  url        = {https://papers.ssrn.com/abstract=3724644},
  urldate    = {2021-03-28},
  abstract   = {Automated text classification has rapidly become an important tool for political analysis.Recent advancements in NLP enabled by advances in deep learning now achieve state of the art results in many standard tasks for the field. However, these methods require large amounts of both computing power and text data to learn the characteristics of the language, resources which are not always accessible to political scientists. One solution is a transfer learning approach, where knowledge learned in one area or source task is transferred to another area or a target task. A class of models that embody this approach are language models, which demonstrate extremely high levels of performance. We investigate the performance of these models in the political science by comparing multiple text classification methods. We find RoBERTa and XLNet, language models that rely on theTransformer, require fewer computing resources and less training data to perform on par with – or outperform – several political science text classification methods. Moreover, we find that the increase in accuracy is especially significant in the case of small labeled data, highlighting the potential for reducing the data-labeling cost of supervised methods for political scientists via the use of pretrained language models.},
  address    = {Rochester, NY},
  keywords   = {text classification, transfer learning, language models, transformers},
  month      = oct,
  shorttitle = {A {Comparison} of {Methods} in {Political} {Science} {Text} {Classification}},
  year       = {2020},
}

@article{kim_convolutional_2014,
	Abstract = {We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.},
	Author = {Kim, Yoon},
	Date-Added = {2019-06-23 08:30:21 +0100},
	Date-Modified = {2019-06-23 08:30:21 +0100},
	File = {arXiv\:1408.5882 PDF:C\:\\Users\\kakia\\Zotero\\storage\\VCCHETZF\\Kim - 2014 - Convolutional Neural Networks for Sentence Classif.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\kakia\\Zotero\\storage\\Z5ADPS7M\\1408.html:text/html},
	Journal = {arXiv:1408.5882 [cs]},
	Keywords = {Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	Month = aug,
	Note = {arXiv: 1408.5882},
	Title = {Convolutional {Neural} {Networks} for {Sentence} {Classification}},
	Url = {http://arxiv.org/abs/1408.5882},
	Urldate = {2018-10-25},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1408.5882}}
